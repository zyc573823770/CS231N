{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gradio InceptionNet v3 Demo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_-55XdJy-Ml",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://gradio.app/static/landing/img/logo_inline.png\" width=\"200px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDmSzM9NyosO",
        "colab_type": "text"
      },
      "source": [
        "Here's a short example notebook that demonstrates how to use the `gradio` python package. \n",
        "\n",
        "We will build a **visual interface** for InceptionNet, a state-of-the-art image classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QEZxZWWyTKi",
        "colab_type": "text"
      },
      "source": [
        "## Install the `gradio` python package and import it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGYdHy3eEIpL",
        "colab_type": "code",
        "outputId": "82b24bee-e3d0-4d9d-bc72-7bdb389bbef8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "!pip install gradio -q"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K    100% |████████████████████████████████| 1.9MB 13.6MB/s \n",
            "\u001b[K    100% |████████████████████████████████| 194kB 30.2MB/s \n",
            "\u001b[K    100% |████████████████████████████████| 61kB 22.9MB/s \n",
            "\u001b[K    100% |████████████████████████████████| 2.3MB 10.3MB/s \n",
            "\u001b[K    100% |████████████████████████████████| 768kB 24.7MB/s \n",
            "\u001b[K    100% |████████████████████████████████| 102kB 28.8MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hA6BTuNtELa9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision.models as models\n",
        "import torch\n",
        "import gradio\n",
        "model = models.resnet101(pretrained=True)\n",
        "class Net(nn.Module):\n",
        "    def forward(self, x):\n",
        "        x = torch.from_numpy(x)\n",
        "        x = model(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UThilKiayYz7",
        "colab_type": "text"
      },
      "source": [
        "## Load (or train) your own model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YohC2oGEyesA",
        "colab_type": "text"
      },
      "source": [
        "## Define the input and output interfaces"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_izWp0WEUCd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inp = gradio.inputs.ImageUpload(shape=(3,224,224))\n",
        "out = gradio.outputs.Label(label_names='imagenet1000', max_label_length=8)\n",
        "# io = gradio.Interface(inputs=inp, \n",
        "#                       outputs=out,\n",
        "#                       model=model)\n",
        "io = gradio.Interface(inputs=\"imageupload\", outputs=\"label\", model=model)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Model type not explicitly identified, inferred to be: python function\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEAFNJhKyje6",
        "colab_type": "text"
      },
      "source": [
        "## Launch the Interfaces"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jv72dJ79XymV",
        "colab_type": "code",
        "outputId": "9e963fe2-105c-4e6f-b065-d19021a67ef3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        }
      },
      "source": [
        "io.launch();"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Validating samples: 1/6  [=.....]\n----------\nValidation failed, likely due to incompatible pre-processing and model input. See below:\n\nTraceback (most recent call last):\n  File \"D:\\App\\Anaconda3\\lib\\site-packages\\gradio\\interface.py\", line 182, in validate\n    prediction = self.predict(processed_input)\n  File \"D:\\App\\Anaconda3\\lib\\site-packages\\gradio\\interface.py\", line 147, in predict\n    return self.model_obj(preprocessed_input)\n  File \"D:\\App\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 532, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"D:\\App\\Anaconda3\\lib\\site-packages\\torchvision\\models\\resnet.py\", line 216, in forward\n    return self._forward_impl(x)\n  File \"D:\\App\\Anaconda3\\lib\\site-packages\\torchvision\\models\\resnet.py\", line 199, in _forward_impl\n    x = self.conv1(x)\n  File \"D:\\App\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 532, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"D:\\App\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 345, in forward\n    return self.conv2d_forward(input, self.weight)\n  File \"D:\\App\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 342, in conv2d_forward\n    self.padding, self.dilation, self.groups)\nTypeError: conv2d(): argument 'input' (position 1) must be Tensor, not numpy.ndarray\n\n"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Validation did not pass",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-32-f854f4c833e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32mD:\\App\\Anaconda3\\lib\\site-packages\\gradio\\interface.py\u001b[0m in \u001b[0;36mlaunch\u001b[1;34m(self, inline, inbrowser, share, validate)\u001b[0m\n\u001b[0;32m    216\u001b[0m         \"\"\"\n\u001b[0;32m    217\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalidate\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate_flag\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[1;31m# If an existing interface is running with this instance, close it.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\App\\Anaconda3\\lib\\site-packages\\gradio\\interface.py\u001b[0m in \u001b[0;36mvalidate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    205\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\\nValidation passed successfully!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Validation did not pass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mlaunch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minbrowser\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshare\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Validation did not pass"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4e2UiXa1ckn",
        "colab_type": "text"
      },
      "source": [
        "**And that's it!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCBBBnX3zTyl",
        "colab_type": "text"
      },
      "source": [
        "## What's next?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4u-QXapJzko7",
        "colab_type": "text"
      },
      "source": [
        "Check out **www.gradio.app** for more examples and documentation. \n",
        "\n",
        "For updates on the `gradio` package (and a sneak peek of beta features), join the [**mailing list**](https://gradio.app/contact.html).\n",
        "\n",
        "And if you have any suggestions, you can reach us at **[gradio.app@gmail.com](mailto:gradio.app@gmail.com)** (and please do!)"
      ]
    }
  ]
}